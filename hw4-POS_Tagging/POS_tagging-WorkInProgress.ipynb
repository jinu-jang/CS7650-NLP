{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rqxpid8J3_xt"
   },
   "source": [
    "# NLP Homework 4 Programming Assignment\n",
    "\n",
    "In this assignment, we will train and evaluate a neural model to tag the parts of speech in a sentence.\n",
    "We will also implement several improvements to the model to test its performance.\n",
    "\n",
    "We will be using English text from the Wall Street Journal, marked with POS tags such as `NNP` (proper noun) and `DT` (determiner).\n",
    "\n",
    "## Building a POS Tagger\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3X367eCR3_x0"
   },
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DtnGNDoA3_x3"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwA2y6OR3_yE"
   },
   "source": [
    "### Preparing Data\n",
    "\n",
    "The relevant data is present in the files `train.txt` and `test.txt`.\n",
    "\n",
    "`train.txt`: The training data is present in this file. The file contains sequences of words and their respective tags. The data is split into 80% training and 20% development to train the model and tune the hyperparameters, respectively. See `load_tag_data` for details on how to read the training data.\n",
    "\n",
    "`test.txt`: The test data is present in the file. Use this file only for final evaluation of the trained models. See `load_txt_data` for details on how to read the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "kFpH2P1A3_yG",
    "outputId": "1c889944-290e-4231-9b34-8c07f777aaf3"
   },
   "outputs": [],
   "source": [
    "def load_tag_data(tag_file):\n",
    "    all_sentences = []\n",
    "    all_tags = []\n",
    "    sent = []\n",
    "    tags = []\n",
    "    with open(tag_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.strip() == \"\":\n",
    "                all_sentences.append(sent)\n",
    "                all_tags.append(tags)\n",
    "                sent = []\n",
    "                tags = []\n",
    "            else:\n",
    "                word, tag, _ = line.strip().split()\n",
    "                sent.append(word)\n",
    "                tags.append(tag)\n",
    "    return all_sentences, all_tags\n",
    "\n",
    "def load_txt_data(txt_file):\n",
    "    all_sentences = []\n",
    "    sent = []\n",
    "    with open(txt_file, 'r') as f:\n",
    "        for line in f:\n",
    "            if(line.strip() == \"\"):\n",
    "                all_sentences.append(sent)\n",
    "                sent = []\n",
    "            else:\n",
    "                word = line.strip()\n",
    "                sent.append(word)\n",
    "    return all_sentences\n",
    "\n",
    "train_sentences, train_tags = load_tag_data('train.txt')\n",
    "test_sentences = load_txt_data('test.txt')\n",
    "\n",
    "unique_tags = set([tag for tag_seq in train_tags for tag in tag_seq])\n",
    "\n",
    "# Create train-val split from train data\n",
    "train_val_data = list(zip(train_sentences, train_tags))\n",
    "random.shuffle(train_val_data)\n",
    "split = int(0.8 * len(train_val_data))\n",
    "training_data = train_val_data[:split]\n",
    "val_data = train_val_data[split:]\n",
    "\n",
    "print(\"Train Data: \", len(training_data))\n",
    "print(\"Val Data: \", len(val_data))\n",
    "print(\"Test Data: \", len(test_sentences))\n",
    "print(\"Total tags: \", len(unique_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tlfliN0J-RzV"
   },
   "source": [
    "### Word-to-Index and Tag-to-Index mapping\n",
    "In order to work with text in Tensor format, we need to map each word to an index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "uojEDun83_yP",
    "outputId": "fb218599-7c4b-4b67-cf4d-929e2e8ce2d5"
   },
   "outputs": [],
   "source": [
    "word_to_idx = {}\n",
    "for sent in train_sentences:\n",
    "    for word in sent:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "\n",
    "for sent in test_sentences:\n",
    "    for word in sent:\n",
    "        if word not in word_to_idx:\n",
    "            word_to_idx[word] = len(word_to_idx)\n",
    "            \n",
    "tag_to_idx = {}\n",
    "for tag in unique_tags:\n",
    "    if tag not in tag_to_idx:\n",
    "        tag_to_idx[tag] = len(tag_to_idx)\n",
    "\n",
    "idx_to_tag = {}\n",
    "for tag in tag_to_idx:\n",
    "    idx_to_tag[tag_to_idx[tag]] = tag\n",
    "\n",
    "print(\"Total tags\", len(tag_to_idx))\n",
    "print(\"Vocab size\", len(word_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H26dqorp3_yX"
   },
   "outputs": [],
   "source": [
    "def prepare_sequence(sent, idx_mapping):\n",
    "    idxs = [idx_mapping[word] for word in sent]\n",
    "    return torch.tensor(idxs, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WRnBTCwD3_yc"
   },
   "source": [
    "### Set up model\n",
    "We will build and train a Basic POS Tagger which is an LSTM model to tag the parts of speech in a given sentence.\n",
    "\n",
    "\n",
    "First we need to define some default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2P5SHabu3_yf"
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 3\n",
    "LEARNING_RATE = 0.1\n",
    "LSTM_LAYERS = 1\n",
    "DROPOUT = 0\n",
    "EPOCHS = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jkkS4oEb3_yk"
   },
   "source": [
    "### Define Model\n",
    "\n",
    "The model takes as input a sentence as a tensor in the index space. This sentence is then converted to embedding space where each word maps to its word embedding. The word embeddings is learned as part of the model training process. \n",
    "\n",
    "These word embeddings act as input to the LSTM which produces a hidden state. This hidden state is then passed to a Linear layer that produces the probability distribution for the tags of every word. The model will output the tag with the highest probability for a given word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCa30HQb3_ym"
   },
   "outputs": [],
   "source": [
    "# class BasicPOSTagger(nn.Module):\n",
    "#     def __init__(self, embedding_dim, hidden_dim, vocab_size, tagset_size):\n",
    "#         super(BasicPOSTagger, self).__init__()\n",
    "#         #############################################################################\n",
    "#         # TODO: Define and initialize anything needed for the forward pass.\n",
    "#         # You are required to create a model with:\n",
    "#         # an embedding layer: that maps words to the embedding space\n",
    "#         # an LSTM layer: that takes word embeddings as input and outputs hidden states\n",
    "#         # a Linear layer: maps from hidden state space to tag space\n",
    "#         #############################################################################\n",
    "        \n",
    "#         #############################################################################\n",
    "#         #                             END OF YOUR CODE                              #\n",
    "#         #############################################################################\n",
    "\n",
    "#     def forward(self, sentence):\n",
    "#         tag_scores = None\n",
    "#         #############################################################################\n",
    "#         # TODO: Implement the forward pass.\n",
    "#         # Given a tokenized index-mapped sentence as the argument, \n",
    "#         # compute the corresponding scores for tags\n",
    "#         # returns:: tag_scores (Tensor)\n",
    "#         #############################################################################\n",
    "        \n",
    "#         #############################################################################\n",
    "#         #                             END OF YOUR CODE                              #\n",
    "#         #############################################################################\n",
    "#         return tag_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ot9J3MrB3_ys"
   },
   "source": [
    "### Training\n",
    "\n",
    "We define train and evaluate procedures that allow us to train our model using our created train-val split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BWMGxh4Z3_yv"
   },
   "outputs": [],
   "source": [
    "# def train(epoch, model, loss_function, optimizer):\n",
    "#     train_loss = 0\n",
    "#     train_examples = 0\n",
    "#     for sentence, tags in training_data:\n",
    "#         #############################################################################\n",
    "#         # TODO: Implement the training loop\n",
    "#         # Hint: you can use the prepare_sequence method for creating index mappings \n",
    "#         # for sentences. Find the gradient with respect to the loss and update the\n",
    "#         # model parameters using the optimizer.\n",
    "#         #############################################################################\n",
    "        \n",
    "#         #############################################################################\n",
    "#         #                             END OF YOUR CODE                              #\n",
    "#         #############################################################################\n",
    "    \n",
    "#     avg_train_loss = train_loss / train_examples\n",
    "#     avg_val_loss, val_accuracy = evaluate(model, loss_function, optimizer)\n",
    "        \n",
    "#     print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\tAvg Val Loss: {:.4f}\\t Val Accuracy: {:.0f}\".format(epoch, \n",
    "#                                                                       EPOCHS, \n",
    "#                                                                       avg_train_loss, \n",
    "#                                                                       avg_val_loss,\n",
    "#                                                                       val_accuracy))\n",
    "\n",
    "# def evaluate(model, loss_function, optimizer):\n",
    "#   # returns:: avg_val_loss (float)\n",
    "#   # returns:: val_accuracy (float)\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_examples = 0\n",
    "#     with torch.no_grad():\n",
    "#         for sentence, tags in val_data:\n",
    "#             #############################################################################\n",
    "#             # TODO: Implement the evaluate loop\n",
    "#             # Find the average validation loss along with the validation accuracy.\n",
    "#             # Hint: To find the accuracy, argmax of tag predictions can be used.\n",
    "#             #############################################################################\n",
    "            \n",
    "#             #############################################################################\n",
    "#             #                             END OF YOUR CODE                              #\n",
    "#             #############################################################################\n",
    "#     val_accuracy = 100. * correct / val_examples\n",
    "#     avg_val_loss = val_loss / val_examples\n",
    "#     return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lsuHjjH1rQeS"
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Initialize the model, optimizer and the loss function\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "for epoch in range(1, EPOCHS + 1): \n",
    "    train(epoch, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "uK6mT_k8NRvB"
   },
   "source": [
    "**Sanity Check!** After 5 epochs you should get around 53% accuracy, after 10 epochs the accuracy should be around 61%, the accuracy rises to around 70% after 20 epochs, and to around 75% accuracy after 30 epochs.\n",
    "\n",
    "**Note1** If you run the notebook on CPU, it could take time to run all 30 epochs. So try the small number of epochs first to sanity check and then run the model for all 30 epochs. You're free to use GPU for this assignment.\n",
    "\n",
    "**Note2** Your accuracy may not match exactly to what is reported here but as long as the trend is increasing, it should be good.\n",
    "\n",
    "**Note3** The reported numbers are with the default hyperparameters. If you reach the desired accuracy, you can try different hyperparameter settings to improve the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a method to save the predictions for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2e9aoWNcNomd"
   },
   "outputs": [],
   "source": [
    "# def test():\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_examples = 0\n",
    "#     predicted_tags = []\n",
    "#     with torch.no_grad():\n",
    "#         for sentence in test_sentences:\n",
    "#             #############################################################################\n",
    "#             # TODO: Implement the test loop\n",
    "#             # This method saves the predicted tags for the sentences in the test set.\n",
    "#             # The tags are first added to a list which is then written to a file for\n",
    "#             # submission. An empty string is added after every sequence of tags\n",
    "#             # corresponding to a sentence to add a newline following file formatting\n",
    "#             # convention, as has been done already.\n",
    "#             #############################################################################\n",
    "            \n",
    "#             #############################################################################\n",
    "#             #                             END OF YOUR CODE                              #\n",
    "#             #############################################################################\n",
    "#             predicted_tags.append(\"\")\n",
    "\n",
    "#     with open('test_labels.txt', 'w+') as f:\n",
    "#         for item in predicted_tags:\n",
    "#             f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "azW08GfZSHcQ"
   },
   "outputs": [],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P9T6s3XTFG46"
   },
   "source": [
    "\n",
    "### Test accuracy\n",
    "\n",
    "Evaluate your performance on the test data by submitting test_labels.txt generated by the method above and **report your test accuracy here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iP64WDReBuDr"
   },
   "source": [
    "Imitate the above method to generate prediction for validation data.\n",
    "Create lists of words, tags predicted by the model and ground truth tags. \n",
    "\n",
    "Use these lists to carry out error analysis to find the top-10 types of errors made by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QgMHr7HCn1x"
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# # TODO: Generate predictions from val data\n",
    "# # Create lists of words, tags predicted by the model and ground truth tags.\n",
    "# #############################################################################\n",
    "# def generate_predictions(model, test_sentences):\n",
    "#     # returns:: word_list (str list)\n",
    "#     # returns:: model_tags (str list)\n",
    "#     # returns:: gt_tags (str list)\n",
    "#     # Your code here\n",
    "#     return word_list, model_tags, gt_tags\n",
    "\n",
    "# #############################################################################\n",
    "# # TODO: Carry out error analysis\n",
    "# # From those lists collected from the above method, find the \n",
    "# # top-10 tuples of (model_tag, ground_truth_tag, frequency, example words)\n",
    "# # sorted by frequency\n",
    "# #############################################################################\n",
    "# def error_analysis(word_list, model_tags, gt_tags):\n",
    "#     # returns: errors (list of tuples)\n",
    "#     # Your code here\n",
    "#     return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PRNjFRDcD2h7"
   },
   "source": [
    "### Error analysis\n",
    "**Report your findings here.**  \n",
    "What kinds of errors did the model make and why do you think it made them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svXyUssdXZ4r"
   },
   "source": [
    "## II. Character level PoS Tagger\n",
    "\n",
    "Use the character-level information present to augment word embeddings. Words that end with -ing or -ly give quite a bit of information about their POS tags. To incorporate this information, run a character level LSTM on every word (treated as a tensor of characters, each mapped to character-index space) to create a character-level representation of the word. Take the last hidden state from the character level LSTM as the representation and concatenate with the word embedding (as in the WordLSTMPoSTagger) to create a new word embedding that captures more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nX4-3AoxSJeY"
   },
   "outputs": [],
   "source": [
    "# Create char to index mapping\n",
    "char_to_idx = {}\n",
    "unique_chars = set()\n",
    "MAX_WORD_LEN = 0\n",
    "\n",
    "for sent in train_sentences:\n",
    "    for word in sent:\n",
    "        for c in word:\n",
    "            unique_chars.add(c)\n",
    "        if len(word) > MAX_WORD_LEN:\n",
    "            MAX_WORD_LEN = len(word)\n",
    "\n",
    "for c in unique_chars:\n",
    "    char_to_idx[c] = len(char_to_idx)\n",
    "char_to_idx[' '] = len(char_to_idx)\n",
    "\n",
    "# New Hyperparameters\n",
    "EMBEDDING_DIM = 6\n",
    "HIDDEN_DIM = 3\n",
    "LEARNING_RATE = 0.1\n",
    "LSTM_LAYERS = 1\n",
    "DROPOUT = 0\n",
    "EPOCHS = 30\n",
    "CHAR_EMBEDDING_DIM = 3\n",
    "CHAR_HIDDEN_DIM = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7U0wb4OeOsde"
   },
   "outputs": [],
   "source": [
    "# class CharPOSTagger(nn.Module):\n",
    "#     def __init__(self, embedding_dim, hidden_dim, char_embedding_dim, \n",
    "#                  char_hidden_dim, char_size, vocab_size, tagset_size):\n",
    "#         super(CharPOSTagger, self).__init__()\n",
    "#         #############################################################################\n",
    "#         # TODO: Define and initialize anything needed for the forward pass.\n",
    "#         # You are required to create a model with:\n",
    "#         # an embedding layer: that maps words to the embedding space\n",
    "#         # an char level LSTM: that finds the character level embedding for a word\n",
    "#         # an LSTM layer: that takes the combined embeddings as input and outputs hidden states\n",
    "#         # a Linear layer: maps from hidden state space to tag space\n",
    "#         #############################################################################\n",
    "        \n",
    "#         #############################################################################\n",
    "#         #                             END OF YOUR CODE                              #\n",
    "#         #############################################################################\n",
    "\n",
    "#     def forward(self, sentence, chars):\n",
    "#         tag_scores = None\n",
    "#         #############################################################################\n",
    "#         # TODO: Implement the forward pass.\n",
    "#         # Given a tokenized index-mapped sentence and a character sequence as the arguments, \n",
    "#         # find the corresponding scores for tags\n",
    "#         # returns:: tag_scores (Tensor)\n",
    "#         #############################################################################\n",
    "        \n",
    "#         #############################################################################\n",
    "#         #                             END OF YOUR CODE                              #\n",
    "#         #############################################################################\n",
    "#         return tag_scores\n",
    "\n",
    "# def train_char(epoch, model, loss_function, optimizer):\n",
    "#     train_loss = 0\n",
    "#     train_examples = 0\n",
    "#     for sentence, tags in training_data:\n",
    "#         #############################################################################\n",
    "#         # TODO: Implement the training loop\n",
    "#         # Hint: you can use the prepare_sequence method for creating index mappings \n",
    "#         # for sentences as well as character sequences. Find the gradient with \n",
    "#         # respect to the loss and update the model parameters using the optimizer.\n",
    "#         #############################################################################\n",
    "        \n",
    "#         #############################################################################\n",
    "#         #                             END OF YOUR CODE                              #\n",
    "#         #############################################################################\n",
    "    \n",
    "#     avg_train_loss = train_loss / train_examples\n",
    "#     avg_val_loss, val_accuracy = evaluate_char(model, loss_function, optimizer)\n",
    "        \n",
    "#     print(\"Epoch: {}/{}\\tAvg Train Loss: {:.4f}\\tAvg Val Loss: {:.4f}\\t Val Accuracy: {:.0f}\".format(epoch, \n",
    "#                                                                       EPOCHS, \n",
    "#                                                                       avg_train_loss, \n",
    "#                                                                       avg_val_loss,\n",
    "#                                                                       val_accuracy))\n",
    "\n",
    "# def evaluate_char(model, loss_function, optimizer):\n",
    "#     # returns:: avg_val_loss (float)\n",
    "#     # returns:: val_accuracy (float)\n",
    "#     val_loss = 0\n",
    "#     correct = 0\n",
    "#     val_examples = 0\n",
    "#     with torch.no_grad():\n",
    "#         for sentence, tags in val_data:\n",
    "#             #############################################################################\n",
    "#             # TODO: Implement the evaluate loop\n",
    "#             # Find the average validation loss along with the validation accuracy.\n",
    "#             # Hint: To find the accuracy, argmax of tag predictions can be used.\n",
    "#             #############################################################################\n",
    "            \n",
    "#             #############################################################################\n",
    "#             #                             END OF YOUR CODE                              #\n",
    "#             #############################################################################\n",
    "#     val_accuracy = 100. * correct / val_examples\n",
    "#     avg_val_loss = val_loss / val_examples\n",
    "#     return avg_val_loss, val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6-QttCw6Otf-"
   },
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "# TODO: Initialize the model, optimizer and the loss function\n",
    "#############################################################################\n",
    "\n",
    "#############################################################################\n",
    "#                             END OF YOUR CODE                              #\n",
    "#############################################################################\n",
    "for epoch in range(1, EPOCHS + 1): \n",
    "    train_char(epoch, model, loss_function, optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xslNYW8EBKMQ"
   },
   "source": [
    "**Sanity Check!** After 5 epochs you should get around 57% accuracy, after 10 epochs the accuracy should be around 67%, the accuracy rises to around 74% after 20 epochs, and to around 77% accuracy after 30 epochs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test accuracy\n",
    "Also evaluate your performance on the test data by submitting test_labels.txt and **report your test accuracy here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IuLl_BSMeovb"
   },
   "source": [
    "### Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Du0raTJreqT2"
   },
   "outputs": [],
   "source": [
    "# #############################################################################\n",
    "# # TODO: Generate predictions from val data\n",
    "# # Create lists of words, tags predicted by the model and ground truth tags.\n",
    "# #############################################################################\n",
    "# def generate_predictions_char(model, test_sentences):\n",
    "#     # returns:: word_list (str list)\n",
    "#     # returns:: model_tags (str list)\n",
    "#     # returns:: gt_tags (str list)\n",
    "#     # Your code here\n",
    "#     return word_list, model_tags, gt_tags\n",
    "\n",
    "# #############################################################################\n",
    "# # TODO: Carry out error analysis\n",
    "# # From those lists collected from the above method, find the \n",
    "# # top-10 tuples of (model_tag, ground_truth_tag, frequency, example words)\n",
    "# # sorted by frequency\n",
    "# #############################################################################\n",
    "# def error_analysis_char(word_list, model_tags, gt_tags):\n",
    "#     # returns: errors (list of tuples)\n",
    "#     # Your code here\n",
    "#     return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5GEP-IgiESzN"
   },
   "source": [
    "\n",
    "**Report your findings here.**  \n",
    "What kinds of errors does the character-level model make as compared to the original model, and why do you think it made them? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LQdc3gH8d_a4"
   },
   "source": [
    "## Modifications\n",
    "\n",
    "Now implement one of the following three modifications and report the model's performance.\n",
    "- Change the number of LSTM layers\n",
    "- Change the number of hidden dimensions\n",
    "- Change the number of word embedding dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modification choice\n",
    "Which modification did you use and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S6NwhSXaBCNl"
   },
   "source": [
    "### Test accuracy\n",
    "Also evaluate your performance on the test data by submitting test_labels.txt and **report your test accuracy here**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xl2C26leFihB"
   },
   "source": [
    "### Error analysis\n",
    "**Report your findings here.**  \n",
    "Compare the top-10 errors made by this modified model with the errors made by the model from part (a). \n",
    "What errors does the original model make as compared to the modified model, and why do you think it made them? \n",
    "\n",
    "Feel free to reuse the methods defined above for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Kh0S5yXIA_0I"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "collapsed_sections": [],
   "name": "POS_tagging.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
